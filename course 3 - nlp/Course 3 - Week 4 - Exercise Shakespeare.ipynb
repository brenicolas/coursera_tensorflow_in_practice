{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOwsuGQQY9OL"
   },
   "outputs": [],
   "source": [
    "# Import the packages\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.utils as ku \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRnDnCW-Z7qv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-10-26 19:02:27--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n",
      "R'esolution de storage.googleapis.com (storage.googleapis.com)... 172.217.19.208\n",
      "Connexion `a storage.googleapis.com (storage.googleapis.com)|172.217.19.208|:443... connect'e.\n",
      "requ^ete HTTP transmise, en attente de la r'eponse... 200 OK\n",
      "Taille : 93578 (91K) [text/plain]\n",
      "Sauvegarde en : << /tmp/sonnets.txt >>\n",
      "\n",
      "/tmp/sonnets.txt    100%[===================>]  91.38K   589KB/s    ds 0.2s    \n",
      "\n",
      "2019-10-26 19:02:28 (589 KB/s) - << /tmp/sonnets.txt >> sauvegard'e [93578/93578]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the data\n",
    "tokenizer = Tokenizer()\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
    "    -O /tmp/sonnets.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data in a corpus\n",
    "data = open('/tmp/sonnets.txt').read()\n",
    "corpus = data.lower().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the corpus\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input sequences using list of tokens\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, \n",
    "                                         maxlen = max_sequence_len, \n",
    "                                         padding = 'pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictors and label\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "label = ku.to_categorical(label, num_classes = total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9vH8Y59ajYL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 10, 100)           321100    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 10, 300)           301200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1605)              162105    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3211)              5156866   \n",
      "=================================================================\n",
      "Total params: 6,101,671\n",
      "Trainable params: 6,101,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length = max_sequence_len - 1))\n",
    "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words/2, activation = 'relu', kernel_regularizer = regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIg2f1HBxqof"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15462 samples\n",
      "Epoch 1/10\n",
      "15462/15462 [==============================] - 99s 6ms/sample - loss: 6.4635 - accuracy: 0.0237\n",
      "Epoch 2/10\n",
      "15462/15462 [==============================] - 90s 6ms/sample - loss: 6.3414 - accuracy: 0.0293\n",
      "Epoch 3/10\n",
      "15462/15462 [==============================] - 90s 6ms/sample - loss: 6.2356 - accuracy: 0.0338\n",
      "Epoch 4/10\n",
      "15462/15462 [==============================] - 91s 6ms/sample - loss: 6.1535 - accuracy: 0.0384\n",
      "Epoch 5/10\n",
      "15462/15462 [==============================] - 90s 6ms/sample - loss: 6.0736 - accuracy: 0.0398\n",
      "Epoch 6/10\n",
      "15462/15462 [==============================] - 91s 6ms/sample - loss: 5.9982 - accuracy: 0.0426\n",
      "Epoch 7/10\n",
      "15462/15462 [==============================] - 90s 6ms/sample - loss: 5.9115 - accuracy: 0.0460\n",
      "Epoch 8/10\n",
      "15462/15462 [==============================] - 84s 5ms/sample - loss: 5.8203 - accuracy: 0.0510\n",
      "Epoch 9/10\n",
      "15462/15462 [==============================] - 81s 5ms/sample - loss: 5.7097 - accuracy: 0.0581\n",
      "Epoch 10/10\n",
      "15462/15462 [==============================] - 81s 5ms/sample - loss: 5.6033 - accuracy: 0.0661\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "history = model.fit(predictors, label, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fXTEO3GJ282"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Vc6PHgxa6Hm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help me Obi Wan Kenobi, you're my only hope and be love in love love in my love and love and love in love and love in love in thee in thee in love be love in thee in thee in love i art love in love i art be love i be be and be and be and be be and be be and be be and be be and be be and be be and be be and be be and be be and be be and be be and be be and be be and be be and be be and be be and be be\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
    "\toutput_word = \"\"\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == predicted:\n",
    "\t\t\toutput_word = word\n",
    "\t\t\tbreak\n",
    "\tseed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NLP_Week4_Exercise_Shakespeare_Answer.ipynb",
   "provenance": [
    {
     "file_id": "1qmXwwCaT07-qviCiBV65lkus_KvwsyQI",
     "timestamp": 1559583256599
    },
    {
     "file_id": "1V60jn23JMcMpwhF-KvCTYIIfm4J2X6v5",
     "timestamp": 1558728367158
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
